{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga modulo comun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('../../common'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from purrfect.dataset import load_partition,save_partition, create_train_valid_loaders\n",
        "\n",
        "from purrfect.training import train_model\n",
        "import torch.optim as optim\n",
        "\n",
        "from purrfect.active_learning import create_new_partition, test_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from purrfect.submission import create_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32\n",
        "USE_AUTOCAST = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DefiniciÃ³n modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ChannelAdder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChannelAdder, self).__init__()\n",
        "        # Define Sobel and Laplacian kernels as tensors\n",
        "        self.sobel_x = torch.tensor([[-1., 0., 1.],\n",
        "                                     [-2., 0., 2.],\n",
        "                                     [-1., 0., 1.]], dtype=torch.float32,device=DEVICE).unsqueeze(0).unsqueeze(0)\n",
        "        \n",
        "        self.sobel_y = torch.tensor([[-1., -2., -1.],\n",
        "                                     [ 0.,  0.,  0.],\n",
        "                                     [ 1.,  2.,  1.]], dtype=torch.float32,device=DEVICE).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        epsilon = 1e-8\n",
        "\n",
        "        # Extract the first, second, and third channels\n",
        "        first_channel = x[:, 0, :, :].unsqueeze(1)  # e1 (first channel)\n",
        "        second_channel = x[:, 1, :, :].unsqueeze(1)  # e2 (second channel)\n",
        "        third_channel = x[:, 2, :, :].unsqueeze(1)  # error (third channel)\n",
        "\n",
        "        # 1. Compute the first new channel: sqrt(first_channel^2 + second_channel^2)\n",
        "        new_channel1 = torch.sqrt(first_channel**2 + second_channel**2)\n",
        "\n",
        "        # 2. Compute the second new channel: 1/2 * arctan(channel2 / channel1)\n",
        "        new_channel2 = 0.5 * torch.atan(second_channel / (first_channel + epsilon))\n",
        "\n",
        "        # 3. Compute Sobel gradients and Laplacians for e1 (first_channel)\n",
        "        grad_e1_x = F.conv2d(first_channel, self.sobel_x, padding=1)\n",
        "        grad_e1_y = F.conv2d(first_channel, self.sobel_y, padding=1)\n",
        "        grad_e1_magnitude = torch.sqrt(grad_e1_x**2 + grad_e1_y**2)\n",
        "\n",
        "        # 4. Compute Sobel gradients and Laplacians for e2 (second_channel)\n",
        "        grad_e2_x = F.conv2d(second_channel, self.sobel_x, padding=1)\n",
        "        grad_e2_y = F.conv2d(second_channel, self.sobel_y, padding=1)\n",
        "        grad_e2_magnitude = torch.sqrt(grad_e2_x**2 + grad_e2_y**2)\n",
        "\n",
        "        # 5. Compute weighted ellipticity channels (e1_weighted, e2_weighted)\n",
        "        #e1_weighted = first_channel / (third_channel + epsilon)\n",
        "        #e2_weighted = second_channel / (third_channel + epsilon)\n",
        "\n",
        "        # Concatenate all the channels (original and new) into the output tensor\n",
        "        output = torch.cat([\n",
        "            x,                 # Original 3 channels\n",
        "            new_channel1,      # sqrt(channel1^2 + channel2^2)\n",
        "            new_channel2,      # 1/2 * arctan(channel2 / channel1)\n",
        "            grad_e1_magnitude, # Gradient magnitude of channel1\n",
        "            grad_e2_magnitude, # Gradient magnitude of channel2\n",
        "        ], dim=1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "BN_MOMENTUM = 0.1\n",
        "def kaiming_init(module,\n",
        "                 a=0,\n",
        "                 mode='fan_out',\n",
        "                 nonlinearity='relu',\n",
        "                 bias=0,\n",
        "                 distribution='normal'):\n",
        "    assert distribution in ['uniform', 'normal']\n",
        "    if distribution == 'uniform':\n",
        "        nn.init.kaiming_uniform_(\n",
        "            module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "    else:\n",
        "        nn.init.kaiming_normal_(\n",
        "            module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "class PSA_s(nn.Module):\n",
        "    def __init__(self, inplanes, planes, kernel_size=1, stride=1):\n",
        "        super(PSA_s, self).__init__()\n",
        "\n",
        "        self.inplanes = inplanes\n",
        "        self.inter_planes = planes // 2\n",
        "        self.planes = planes\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = (kernel_size - 1) // 2\n",
        "        ratio = 4\n",
        "\n",
        "        self.conv_q_right = nn.Conv2d(self.inplanes, 1, kernel_size=1, stride=stride, padding=0, bias=False)\n",
        "        self.conv_v_right = nn.Conv2d(self.inplanes, self.inter_planes, kernel_size=1, stride=stride, padding=0,\n",
        "                                      bias=False)\n",
        "        # self.conv_up = nn.Conv2d(self.inter_planes, self.planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.conv_up = nn.Sequential(\n",
        "            nn.Conv2d(self.inter_planes, self.inter_planes // ratio, kernel_size=1),\n",
        "            nn.LayerNorm([self.inter_planes // ratio, 1, 1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.inter_planes // ratio, self.planes, kernel_size=1)\n",
        "        )\n",
        "        self.softmax_right = nn.Softmax(dim=2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.conv_q_left = nn.Conv2d(self.inplanes, self.inter_planes, kernel_size=1, stride=stride, padding=0,\n",
        "                                     bias=False)  # g\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv_v_left = nn.Conv2d(self.inplanes, self.inter_planes, kernel_size=1, stride=stride, padding=0,\n",
        "                                     bias=False)  # theta\n",
        "        self.softmax_left = nn.Softmax(dim=2)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        kaiming_init(self.conv_q_right, mode='fan_in')\n",
        "        kaiming_init(self.conv_v_right, mode='fan_in')\n",
        "        kaiming_init(self.conv_q_left, mode='fan_in')\n",
        "        kaiming_init(self.conv_v_left, mode='fan_in')\n",
        "\n",
        "        self.conv_q_right.inited = True\n",
        "        self.conv_v_right.inited = True\n",
        "        self.conv_q_left.inited = True\n",
        "        self.conv_v_left.inited = True\n",
        "\n",
        "    def spatial_pool(self, x):\n",
        "        input_x = self.conv_v_right(x)\n",
        "\n",
        "        batch, channel, height, width = input_x.size()\n",
        "\n",
        "        # [N, IC, H*W]\n",
        "        input_x = input_x.view(batch, channel, height * width)\n",
        "\n",
        "        # [N, 1, H, W]\n",
        "        context_mask = self.conv_q_right(x)\n",
        "\n",
        "        # [N, 1, H*W]\n",
        "        context_mask = context_mask.view(batch, 1, height * width)\n",
        "\n",
        "        # [N, 1, H*W]\n",
        "        context_mask = self.softmax_right(context_mask)\n",
        "\n",
        "        # [N, IC, 1]\n",
        "        # context = torch.einsum('ndw,new->nde', input_x, context_mask)\n",
        "        context = torch.matmul(input_x, context_mask.transpose(1, 2))\n",
        "\n",
        "        # [N, IC, 1, 1]\n",
        "        context = context.unsqueeze(-1)\n",
        "\n",
        "        # [N, OC, 1, 1]\n",
        "        context = self.conv_up(context)\n",
        "\n",
        "        # [N, OC, 1, 1]\n",
        "        mask_ch = self.sigmoid(context)\n",
        "\n",
        "        out = x * mask_ch\n",
        "\n",
        "        return out\n",
        "\n",
        "    def channel_pool(self, x):\n",
        "        # [N, IC, H, W]\n",
        "        g_x = self.conv_q_left(x)\n",
        "\n",
        "        batch, channel, height, width = g_x.size()\n",
        "\n",
        "        # [N, IC, 1, 1]\n",
        "        avg_x = self.avg_pool(g_x)\n",
        "\n",
        "        batch, channel, avg_x_h, avg_x_w = avg_x.size()\n",
        "\n",
        "        # [N, 1, IC]\n",
        "        avg_x = avg_x.view(batch, channel, avg_x_h * avg_x_w).permute(0, 2, 1)\n",
        "\n",
        "        # [N, IC, H*W]\n",
        "        theta_x = self.conv_v_left(x).view(batch, self.inter_planes, height * width)\n",
        "\n",
        "        # [N, IC, H*W]\n",
        "        theta_x = self.softmax_left(theta_x)\n",
        "\n",
        "        # [N, 1, H*W]\n",
        "        # context = torch.einsum('nde,new->ndw', avg_x, theta_x)\n",
        "        context = torch.matmul(avg_x, theta_x)\n",
        "\n",
        "        # [N, 1, H, W]\n",
        "        context = context.view(batch, 1, height, width)\n",
        "\n",
        "        # [N, 1, H, W]\n",
        "        mask_sp = self.sigmoid(context)\n",
        "\n",
        "        out = x * mask_sp\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        # [N, C, H, W]\n",
        "        out = self.spatial_pool(x)\n",
        "\n",
        "        # [N, C, H, W]\n",
        "        out = self.channel_pool(out)\n",
        "\n",
        "        # [N, C, H, W]\n",
        "        # out = context_spatial + context_channel\n",
        "\n",
        "        return out\n",
        "\n",
        "class ConBnRelu(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,bias=False):\n",
        "        super(ConBnRelu, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                              dilation=dilation, bias=bias)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, momentum=BN_MOMENTUM)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "class DoubleConv(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, use_attention=False):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        if use_attention:\n",
        "            self.seq = nn.Sequential(\n",
        "                ConBnRelu(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                PSA_s(out_channels, out_channels),\n",
        "                ConBnRelu(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            )\n",
        "        else:\n",
        "            self.seq = nn.Sequential(\n",
        "                ConBnRelu(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                ConBnRelu(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            )\n",
        "\n",
        "        self.rescale = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq(x) + self.rescale(x)\n",
        "\n",
        "\n",
        "# Define the U-Net model\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        # Channel Adder\n",
        "        self.channel_adder = ChannelAdder() # 3x128x128 -> 5x128x128\n",
        "        # Encoder\n",
        "        self.encoder1 = DoubleConv(in_channels+4, 64) # 6x128x128 -> 64x128x128\n",
        "        self.encoder2 = nn.Sequential(\n",
        "            nn.MaxPool2d(2), # 64x128x128 -> 64x64x64\n",
        "            DoubleConv(64, 128) # 64x64x64 -> 128x64x64\n",
        "        )\n",
        "        \n",
        "        #self.encoder3 = nn.Sequential(\n",
        "        #    nn.MaxPool2d(2), # 128x64x64 -> 128x32x32\n",
        "        #    DoubleConv(128, 256) # 128x32x32 -> 256x32x32\n",
        "        #)\n",
        "        #self.encoder4 = nn.Sequential(\n",
        "        #    nn.MaxPool2d(2), # 256x32x32 -> 256x16x16\n",
        "        #    DoubleConv(256, 512) # 256x16x16 -> 512x16x16\n",
        "        #)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.MaxPool2d(2), # 128x64x64 -> 128x32x32\n",
        "            DoubleConv(128, 256) # 128x32x32 -> 256x32x32\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        #self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2) # 1024x8x8 -> 512x16x16\n",
        "        # concat 512x16x16 + 512x16x16 -> 1024x16x16\n",
        "        #self.decoder4 = DoubleConv(1024, 512) # 1024x16x16 -> 512x16x16\n",
        "        \n",
        "        #self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) # 512x16x16 -> 256x32x32\n",
        "        # concat 256x32x32 + 256x32x32 -> 512x32x32\n",
        "        #self.decoder3 = DoubleConv(512, 256)   # 512x32x32 -> 256x32x32\n",
        "        \n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) # 256x32x32 -> 128x64x64\n",
        "        # concat 128x64x64 + 128x64x64 -> 256x64x64\n",
        "        self.decoder2 = DoubleConv(256, 128) # 256x64x64 -> 128x64x64\n",
        "        \n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2) # 128x64x64 -> 64x128x128\n",
        "        # concat 64x128x128 + 64x128x128 -> 128x128x128\n",
        "        self.decoder1 = nn.Sequential(\n",
        "            DoubleConv(128, 64), # 128x128x128 -> 64x128x128\n",
        "            nn.Conv2d(64, out_channels, kernel_size=1) # 64x128x128 -> 1x128x128\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        F.max_pool2d(x, 2)\n",
        "        # Agregar features\n",
        "        x = self.channel_adder(x)\n",
        "        # Encoder\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        #e3 = self.encoder3(e2)\n",
        "        #e4 = self.encoder4(e3)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(e2)\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        #d4 = self.upconv4(b)\n",
        "        #d4 = torch.cat((e4, d4), dim=1)\n",
        "        #d4 = self.decoder4(d4)\n",
        "\n",
        "        #d3 = self.upconv3(b)\n",
        "        #d3 = torch.cat((e3, d3), dim=1)\n",
        "        #d3 = self.decoder3(d3)\n",
        "\n",
        "        d2 = self.upconv2(b)\n",
        "        d2 = torch.cat((e2, d2), dim=1)\n",
        "        d2 = self.decoder2(d2)\n",
        "\n",
        "        d1 = self.upconv1(d2)\n",
        "        d1 = torch.cat((e1, d1), dim=1)\n",
        "        out = self.decoder1(d1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CreaciÃ³n particion inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_next_partitions(current_partition,k=5):#Creacion de particiones train y valid\n",
        "    init_partition = []\n",
        "    for i in range(k):\n",
        "        init_partition += load_partition(f\"partition_{k*current_partition+(i+1)}.json\")\n",
        "        #print(f\"partition_{k*current_partition+(i+1)}.json\")\n",
        "\n",
        "    train_partition, val_partition = train_test_split(init_partition, test_size=0.2, random_state=42)\n",
        "    save_partition(f\"partition_{current_partition+1}_train.json\",\"partitions\",train_partition)\n",
        "    save_partition(f\"partition_{current_partition+1}_val.json\",\"partitions\",val_partition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_next_partitions(0,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Define model\n",
        "model = UNet(3,1)\n",
        "model = model.to(DEVICE)\n",
        "# Define Loss\n",
        "criterion = torch.nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1948801"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum([p.numel() for p in model.parameters() if p.requires_grad])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rYf70y6AJmLe"
      },
      "outputs": [],
      "source": [
        "current_partition = 1\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 8: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.88it/s, WMAPE=3.7, DICE=0.149, DPEAKS=92.8, Loss=0.0119]\n",
            "Validate Epoch 8: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.18it/s, WMAPE=5.73, DICE=0.163, DPEAKS=115, Loss=0.0163]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 9: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.88it/s, WMAPE=3.39, DICE=0.142, DPEAKS=90.7, Loss=0.0109]\n",
            "Validate Epoch 9: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.12it/s, WMAPE=2.96, DICE=0.156, DPEAKS=101, Loss=0.012]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [10/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 10: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.87it/s, WMAPE=3.34, DICE=0.137, DPEAKS=86.9, Loss=0.0107]\n",
            "Validate Epoch 10: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.18it/s, WMAPE=4.9, DICE=0.146, DPEAKS=163, Loss=0.0148]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 11: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.87it/s, WMAPE=3.15, DICE=0.132, DPEAKS=86.5, Loss=0.0101]\n",
            "Validate Epoch 11: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.06it/s, WMAPE=4.42, DICE=0.14, DPEAKS=85.7, Loss=0.0135]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 12: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.87it/s, WMAPE=3.13, DICE=0.131, DPEAKS=84.7, Loss=0.0101]\n",
            "Validate Epoch 12: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.36it/s, WMAPE=4.67, DICE=0.156, DPEAKS=89.8, Loss=0.0133]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 13: 100%|ââââââââââ| 154/154 [00:50<00:00,  3.06it/s, WMAPE=3, DICE=0.127, DPEAKS=82.9, Loss=0.00952]\n",
            "Validate Epoch 13: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.19it/s, WMAPE=3.17, DICE=0.139, DPEAKS=87.3, Loss=0.0101]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [14/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 14: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.88it/s, WMAPE=2.95, DICE=0.125, DPEAKS=79.9, Loss=0.00931]\n",
            "Validate Epoch 14: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.06it/s, WMAPE=6.35, DICE=0.155, DPEAKS=118, Loss=0.018]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 15: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.86it/s, WMAPE=2.92, DICE=0.125, DPEAKS=79.9, Loss=0.00937]\n",
            "Validate Epoch 15: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.18it/s, WMAPE=2.93, DICE=0.132, DPEAKS=82, Loss=0.00978]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [16/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 16: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.88it/s, WMAPE=2.83, DICE=0.121, DPEAKS=78.3, Loss=0.00913]\n",
            "Validate Epoch 16: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.12it/s, WMAPE=3.43, DICE=0.129, DPEAKS=77.8, Loss=0.00984]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 17: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.87it/s, WMAPE=2.75, DICE=0.117, DPEAKS=75.5, Loss=0.00866]\n",
            "Validate Epoch 17: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.14it/s, WMAPE=6.39, DICE=0.155, DPEAKS=111, Loss=0.0178]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 18: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.87it/s, WMAPE=2.75, DICE=0.117, DPEAKS=77.6, Loss=0.00872]\n",
            "Validate Epoch 18: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.28it/s, WMAPE=3.42, DICE=0.133, DPEAKS=82.5, Loss=0.0115]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 19: 100%|ââââââââââ| 154/154 [00:52<00:00,  2.93it/s, WMAPE=2.67, DICE=0.114, DPEAKS=74.8, Loss=0.00848]\n",
            "Validate Epoch 19: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.22it/s, WMAPE=6.93, DICE=0.15, DPEAKS=91.9, Loss=0.019]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 20: 100%|ââââââââââ| 154/154 [00:53<00:00,  2.88it/s, WMAPE=2.66, DICE=0.114, DPEAKS=75.4, Loss=0.00841]\n",
            "Validate Epoch 20: 100%|ââââââââââ| 39/39 [00:06<00:00,  6.21it/s, WMAPE=5.35, DICE=0.134, DPEAKS=92.6, Loss=0.017]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "early stopping: 5 epochs without improvement\n",
            "Training complete.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader = create_train_valid_loaders(\n",
        "    f\"partition_{current_partition}_train.json\",\n",
        "    f\"partition_{current_partition}_val.json\",\n",
        "    \"partitions\",\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")\n",
        "last_checkpoint_path = os.path.join(\n",
        "    \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    best_model_path,\n",
        "    last_checkpoint_path,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=50,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=5,\n",
        "    use_autocast=USE_AUTOCAST\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validate Epoch test: 100%|ââââââââââ| 486/486 [03:38<00:00,  2.22it/s, WMAPE=2.94, DICE=0.132, DPEAKS=80.6, Loss=0.00988]\n"
          ]
        }
      ],
      "source": [
        "#Cargar mejor modelo de la particion actual\n",
        "model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "test_model(model,criterion,device=DEVICE,batch_size=BATCH_SIZE*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_next_partitions(current_partition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_partition = 1\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")\n",
        "last_checkpoint_path = os.path.join(\n",
        "    \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        ")\n",
        "model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "optimizer = optim.Adam(model.parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|ââââââââââ| 307/307 [02:03<00:00,  2.48it/s, WMAPE=1.93, DICE=0.0569, DPEAKS=44.2, Loss=0.00614]\n",
            "Validate Epoch 1: 100%|ââââââââââ| 77/77 [00:13<00:00,  5.81it/s, WMAPE=4.07, DICE=0.0575, DPEAKS=39, Loss=0.0121]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [2/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2: 100%|ââââââââââ| 307/307 [02:00<00:00,  2.54it/s, WMAPE=1.79, DICE=0.0535, DPEAKS=40, Loss=0.00565]\n",
            "Validate Epoch 2: 100%|ââââââââââ| 77/77 [00:13<00:00,  5.77it/s, WMAPE=3.13, DICE=0.0565, DPEAKS=43.7, Loss=0.00952]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [3/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3: 100%|ââââââââââ| 307/307 [02:03<00:00,  2.49it/s, WMAPE=1.64, DICE=0.0518, DPEAKS=38.2, Loss=0.0052]\n",
            "Validate Epoch 3: 100%|ââââââââââ| 77/77 [00:14<00:00,  5.32it/s, WMAPE=1.83, DICE=0.0536, DPEAKS=37.7, Loss=0.0056]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [4/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4: 100%|ââââââââââ| 307/307 [02:07<00:00,  2.41it/s, WMAPE=1.55, DICE=0.0509, DPEAKS=37, Loss=0.00493]\n",
            "Validate Epoch 4: 100%|ââââââââââ| 77/77 [00:13<00:00,  5.72it/s, WMAPE=2.39, DICE=0.0547, DPEAKS=42.5, Loss=0.00706]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 5: 100%|ââââââââââ| 307/307 [01:59<00:00,  2.57it/s, WMAPE=1.5, DICE=0.0513, DPEAKS=39.2, Loss=0.0048]\n",
            "Validate Epoch 5: 100%|ââââââââââ| 77/77 [00:14<00:00,  5.29it/s, WMAPE=2.94, DICE=0.0585, DPEAKS=45.8, Loss=0.00939]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 6: 100%|ââââââââââ| 307/307 [02:09<00:00,  2.37it/s, WMAPE=1.39, DICE=0.0475, DPEAKS=35.2, Loss=0.00441]\n",
            "Validate Epoch 6: 100%|ââââââââââ| 77/77 [00:14<00:00,  5.23it/s, WMAPE=5.61, DICE=0.0714, DPEAKS=64.4, Loss=0.0174]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "early stopping: 3 epochs without improvement\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "current_partition=2\n",
        "train_loader, val_loader = create_train_valid_loaders(\n",
        "    f\"partition_{current_partition}_train.json\",\n",
        "    f\"partition_{current_partition}_val.json\",\n",
        "    \"partitions\",\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")\n",
        "last_checkpoint_path = os.path.join(\n",
        "    \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        ")\n",
        "train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    best_model_path,\n",
        "    last_checkpoint_path,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=50,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validate Epoch test: 100%|ââââââââââ| 971/971 [03:04<00:00,  5.28it/s, WMAPE=1.82, DICE=0.0536, DPEAKS=39, Loss=0.00555]\n"
          ]
        }
      ],
      "source": [
        "#Cargar mejor modelo de la particion actual\n",
        "model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "#optimizer.load_state_dict(torch.load(last_checkpoint_path,weights_only=True)[\"optimizer\"])\n",
        "test_model(model,criterion,device=DEVICE,batch_size=BATCH_SIZE)\n",
        "create_next_partitions(current_partition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for current_partition in range(3,9):\n",
        "    train_loader, val_loader = create_train_valid_loaders(\n",
        "        f\"partition_{current_partition}_train.json\",\n",
        "        f\"partition_{current_partition}_val.json\",\n",
        "        \"partitions\",\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        "    best_model_path = os.path.join(\n",
        "        \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        "    )\n",
        "    last_checkpoint_path = os.path.join(\n",
        "        \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        "    )\n",
        "    train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        best_model_path,\n",
        "        last_checkpoint_path,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        num_epochs=50,\n",
        "        device=DEVICE,\n",
        "        early_stopping_patience=3,\n",
        "    )\n",
        "    model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    optimizer.load_state_dict(torch.load(last_checkpoint_path,weights_only=True)[\"optimizer\"])\n",
        "    test_model(model,criterion,device=DEVICE,batch_size=BATCH_SIZE)\n",
        "    create_next_partitions(current_partition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_partition=3\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")\n",
        "last_checkpoint_path = os.path.join(\n",
        "    \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|ââââââââââ| 307/307 [02:14<00:00,  2.29it/s, WMAPE=2.29, DICE=0.0699, DPEAKS=55.9, Loss=0.00713]\n",
            "Validate Epoch 1: 100%|ââââââââââ| 77/77 [00:12<00:00,  5.96it/s, WMAPE=2.03, DICE=0.0603, DPEAKS=61.1, Loss=0.00608]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [2/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2: 100%|ââââââââââ| 307/307 [02:02<00:00,  2.50it/s, WMAPE=1.94, DICE=0.0513, DPEAKS=44, Loss=0.00605]\n",
            "Validate Epoch 2: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.13it/s, WMAPE=5.36, DICE=0.0579, DPEAKS=45, Loss=0.0157]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3: 100%|ââââââââââ| 307/307 [02:03<00:00,  2.49it/s, WMAPE=1.87, DICE=0.0494, DPEAKS=44.1, Loss=0.00577]\n",
            "Validate Epoch 3: 100%|ââââââââââ| 77/77 [00:11<00:00,  6.76it/s, WMAPE=1.72, DICE=0.0499, DPEAKS=39.2, Loss=0.00549]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [4/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4: 100%|ââââââââââ| 307/307 [02:00<00:00,  2.55it/s, WMAPE=1.83, DICE=0.0476, DPEAKS=39.6, Loss=0.00563]\n",
            "Validate Epoch 4: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.16it/s, WMAPE=3.16, DICE=0.05, DPEAKS=41.1, Loss=0.00857]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 5: 100%|ââââââââââ| 307/307 [01:59<00:00,  2.58it/s, WMAPE=1.9, DICE=0.0493, DPEAKS=43, Loss=0.00583]\n",
            "Validate Epoch 5: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.17it/s, WMAPE=2.04, DICE=0.0634, DPEAKS=56.6, Loss=0.00611]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 6: 100%|ââââââââââ| 307/307 [02:00<00:00,  2.54it/s, WMAPE=1.79, DICE=0.0456, DPEAKS=38.7, Loss=0.00552]\n",
            "Validate Epoch 6: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.17it/s, WMAPE=2.73, DICE=0.0758, DPEAKS=71.2, Loss=0.0079]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "early stopping: 3 epochs without improvement\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader = create_train_valid_loaders(\n",
        "    f\"partition_{current_partition}_train.json\",\n",
        "    f\"partition_{current_partition}_val.json\",\n",
        "    \"partitions\",\n",
        "    batch_size=16,\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    best_model_path,\n",
        "    last_checkpoint_path,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=50,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validate Epoch test: 100%|ââââââââââ| 1941/1941 [04:54<00:00,  6.59it/s, WMAPE=1.77, DICE=0.0499, DPEAKS=38.4, Loss=0.00553]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "create_next_partitions() missing 2 required positional arguments: 'model' and 'criterion'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(best_model_path,weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      3\u001b[0m test_model(model,criterion,device\u001b[38;5;241m=\u001b[39mDEVICE,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcreate_next_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_partition\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: create_next_partitions() missing 2 required positional arguments: 'model' and 'criterion'"
          ]
        }
      ],
      "source": [
        "#Cargar mejor modelo de la particion actual\n",
        "model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "test_model(model,criterion,device=DEVICE,batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_next_partitions(current_partition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_partition=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|ââââââââââ| 307/307 [02:14<00:00,  2.28it/s, WMAPE=1.7, DICE=0.0421, DPEAKS=32.6, Loss=0.0052]\n",
            "Validate Epoch 1: 100%|ââââââââââ| 77/77 [00:12<00:00,  6.06it/s, WMAPE=1.51, DICE=0.0393, DPEAKS=27.1, Loss=0.00439]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [2/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2: 100%|ââââââââââ| 307/307 [02:04<00:00,  2.47it/s, WMAPE=1.69, DICE=0.041, DPEAKS=32.5, Loss=0.00514]\n",
            "Validate Epoch 2: 100%|ââââââââââ| 77/77 [00:11<00:00,  6.91it/s, WMAPE=1.72, DICE=0.0389, DPEAKS=28.4, Loss=0.00493]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3: 100%|ââââââââââ| 307/307 [02:02<00:00,  2.51it/s, WMAPE=1.67, DICE=0.0407, DPEAKS=32, Loss=0.00506]\n",
            "Validate Epoch 3: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.11it/s, WMAPE=1.48, DICE=0.0388, DPEAKS=28, Loss=0.0043]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [4/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4: 100%|ââââââââââ| 307/307 [02:04<00:00,  2.46it/s, WMAPE=1.63, DICE=0.0406, DPEAKS=30.3, Loss=0.00496]\n",
            "Validate Epoch 4: 100%|ââââââââââ| 77/77 [00:11<00:00,  6.81it/s, WMAPE=1.46, DICE=0.039, DPEAKS=27.4, Loss=0.00426]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [5/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 5: 100%|ââââââââââ| 307/307 [02:03<00:00,  2.48it/s, WMAPE=1.64, DICE=0.0403, DPEAKS=31.1, Loss=0.00503]\n",
            "Validate Epoch 5: 100%|ââââââââââ| 77/77 [00:11<00:00,  6.88it/s, WMAPE=1.65, DICE=0.0381, DPEAKS=26.7, Loss=0.00478]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 6: 100%|ââââââââââ| 307/307 [02:02<00:00,  2.51it/s, WMAPE=1.63, DICE=0.0404, DPEAKS=31, Loss=0.00503]\n",
            "Validate Epoch 6: 100%|ââââââââââ| 77/77 [00:11<00:00,  6.90it/s, WMAPE=1.43, DICE=0.0383, DPEAKS=27.1, Loss=0.00422]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [7/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 7: 100%|ââââââââââ| 307/307 [02:05<00:00,  2.44it/s, WMAPE=1.62, DICE=0.04, DPEAKS=30.8, Loss=0.00497]\n",
            "Validate Epoch 7: 100%|ââââââââââ| 77/77 [00:11<00:00,  6.61it/s, WMAPE=1.53, DICE=0.0381, DPEAKS=27.1, Loss=0.00434]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 8: 100%|ââââââââââ| 307/307 [02:03<00:00,  2.48it/s, WMAPE=1.62, DICE=0.04, DPEAKS=30.7, Loss=0.00497]\n",
            "Validate Epoch 8: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.07it/s, WMAPE=1.45, DICE=0.0379, DPEAKS=27.2, Loss=0.00424]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 9: 100%|ââââââââââ| 307/307 [02:04<00:00,  2.47it/s, WMAPE=1.61, DICE=0.0399, DPEAKS=30.7, Loss=0.00495]\n",
            "Validate Epoch 9: 100%|ââââââââââ| 77/77 [00:11<00:00,  6.50it/s, WMAPE=1.41, DICE=0.038, DPEAKS=26.9, Loss=0.00424]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "early stopping: 3 epochs without improvement\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader = create_train_valid_loaders(\n",
        "    f\"partition_{current_partition}_train.json\",\n",
        "    f\"partition_{current_partition}_val.json\",\n",
        "    \"partitions\",\n",
        "    batch_size=16,\n",
        ")\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")\n",
        "last_checkpoint_path = os.path.join(\n",
        "    \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    best_model_path,\n",
        "    last_checkpoint_path,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=50,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validate Epoch test: 100%|ââââââââââ| 1941/1941 [04:50<00:00,  6.68it/s, WMAPE=1.41, DICE=0.0383, DPEAKS=28.1, Loss=0.00421]\n"
          ]
        }
      ],
      "source": [
        "#Cargar mejor modelo de la particion actual\n",
        "model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "test_model(model,criterion,device=DEVICE,batch_size=16)\n",
        "create_next_partitions(current_partition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_partition=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|ââââââââââ| 307/307 [01:41<00:00,  3.01it/s, WMAPE=2.11, DICE=0.0473, DPEAKS=47.9, Loss=0.00575]\n",
            "Validate Epoch 1: 100%|ââââââââââ| 77/77 [00:09<00:00,  7.86it/s, WMAPE=1.87, DICE=0.0453, DPEAKS=46.4, Loss=0.00513]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [2/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2: 100%|ââââââââââ| 307/307 [01:40<00:00,  3.05it/s, WMAPE=2.07, DICE=0.0471, DPEAKS=47.3, Loss=0.00562]\n",
            "Validate Epoch 2: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.59it/s, WMAPE=1.97, DICE=0.0453, DPEAKS=44, Loss=0.00521]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3: 100%|ââââââââââ| 307/307 [01:39<00:00,  3.08it/s, WMAPE=2.07, DICE=0.0471, DPEAKS=47.2, Loss=0.00578]\n",
            "Validate Epoch 3: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.01it/s, WMAPE=2.45, DICE=0.0461, DPEAKS=44, Loss=0.00671]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4: 100%|ââââââââââ| 307/307 [01:39<00:00,  3.09it/s, WMAPE=2.09, DICE=0.047, DPEAKS=46.6, Loss=0.00569]\n",
            "Validate Epoch 4: 100%|ââââââââââ| 77/77 [00:09<00:00,  7.87it/s, WMAPE=1.92, DICE=0.0455, DPEAKS=45.8, Loss=0.00514]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "early stopping: 3 epochs without improvement\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader = create_train_valid_loaders(\n",
        "    f\"partition_{current_partition}_train.json\",\n",
        "    f\"partition_{current_partition}_val.json\",\n",
        "    \"partitions\",\n",
        "    batch_size=16,\n",
        ")\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")\n",
        "last_checkpoint_path = os.path.join(\n",
        "    \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    best_model_path,\n",
        "    last_checkpoint_path,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=50,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validate Epoch test: 100%|ââââââââââ| 1941/1941 [04:08<00:00,  7.82it/s, WMAPE=1.51, DICE=0.0433, DPEAKS=33, Loss=0.0046]\n",
            "Validate Epoch partition_6_train: 100%|ââââââââââ| 307/307 [00:42<00:00,  7.16it/s, WMAPE=1.53, DICE=0.0433, DPEAKS=33, Loss=0.00465]\n",
            "Validate Epoch partition_6_val: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.21it/s, WMAPE=1.65, DICE=0.0436, DPEAKS=36.1, Loss=0.00477]\n"
          ]
        }
      ],
      "source": [
        "#Cargar mejor modelo de la particion actual\n",
        "model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "test_model(model,criterion,device=DEVICE,batch_size=16)\n",
        "create_next_partitions(current_partition,model,criterion,device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_partition=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|ââââââââââ| 307/307 [01:39<00:00,  3.08it/s, WMAPE=2.12, DICE=0.048, DPEAKS=50.3, Loss=0.00585]\n",
            "Validate Epoch 1: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.14it/s, WMAPE=2.05, DICE=0.046, DPEAKS=52.4, Loss=0.00538]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [2/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.12it/s, WMAPE=2.13, DICE=0.0478, DPEAKS=49.1, Loss=0.00582]\n",
            "Validate Epoch 2: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.04it/s, WMAPE=2.06, DICE=0.0462, DPEAKS=52.8, Loss=0.00534]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [3/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.12it/s, WMAPE=2.12, DICE=0.0478, DPEAKS=49.1, Loss=0.00574]\n",
            "Validate Epoch 3: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.10it/s, WMAPE=2.07, DICE=0.0464, DPEAKS=52.6, Loss=0.00533]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [4/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.11it/s, WMAPE=2.15, DICE=0.0478, DPEAKS=49.6, Loss=0.00582]\n",
            "Validate Epoch 4: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.02it/s, WMAPE=2.12, DICE=0.0466, DPEAKS=52.3, Loss=0.00537]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 5: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.11it/s, WMAPE=2.08, DICE=0.0475, DPEAKS=49.3, Loss=0.00571]\n",
            "Validate Epoch 5: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.07it/s, WMAPE=2.06, DICE=0.046, DPEAKS=52, Loss=0.00531]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [6/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 6: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.11it/s, WMAPE=2.12, DICE=0.0473, DPEAKS=49.6, Loss=0.00581]\n",
            "Validate Epoch 6: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.08it/s, WMAPE=2.02, DICE=0.046, DPEAKS=51.6, Loss=0.00532]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 7: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.11it/s, WMAPE=2.07, DICE=0.0475, DPEAKS=49.1, Loss=0.00568]\n",
            "Validate Epoch 7: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.05it/s, WMAPE=2.03, DICE=0.0454, DPEAKS=51.4, Loss=0.00528]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [8/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 8: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.11it/s, WMAPE=2.07, DICE=0.0473, DPEAKS=49.8, Loss=0.00567]\n",
            "Validate Epoch 8: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.07it/s, WMAPE=2.01, DICE=0.0452, DPEAKS=49.2, Loss=0.00527]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [9/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 9: 100%|ââââââââââ| 307/307 [01:38<00:00,  3.11it/s, WMAPE=2.13, DICE=0.0473, DPEAKS=48.4, Loss=0.00579]\n",
            "Validate Epoch 9: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.06it/s, WMAPE=2.05, DICE=0.0462, DPEAKS=50.6, Loss=0.00529]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 10: 100%|ââââââââââ| 307/307 [01:37<00:00,  3.14it/s, WMAPE=2.11, DICE=0.047, DPEAKS=48.1, Loss=0.00573]\n",
            "Validate Epoch 10: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.08it/s, WMAPE=2.08, DICE=0.0455, DPEAKS=52.3, Loss=0.00549]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 11: 100%|ââââââââââ| 307/307 [01:37<00:00,  3.14it/s, WMAPE=2.1, DICE=0.047, DPEAKS=48.6, Loss=0.00571]\n",
            "Validate Epoch 11: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.14it/s, WMAPE=1.99, DICE=0.045, DPEAKS=49.5, Loss=0.00524]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [12/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 12: 100%|ââââââââââ| 307/307 [01:37<00:00,  3.14it/s, WMAPE=2.08, DICE=0.047, DPEAKS=48.2, Loss=0.00565]\n",
            "Validate Epoch 12: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.12it/s, WMAPE=2.03, DICE=0.0455, DPEAKS=50.6, Loss=0.00523]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model\n",
            "Epoch [13/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 13: 100%|ââââââââââ| 307/307 [01:37<00:00,  3.14it/s, WMAPE=2.1, DICE=0.0469, DPEAKS=48.8, Loss=0.00565]\n",
            "Validate Epoch 13: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.15it/s, WMAPE=2.02, DICE=0.0451, DPEAKS=49.2, Loss=0.00525]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 14: 100%|ââââââââââ| 307/307 [01:37<00:00,  3.14it/s, WMAPE=2.1, DICE=0.0467, DPEAKS=48.1, Loss=0.00572]\n",
            "Validate Epoch 14: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.05it/s, WMAPE=2.14, DICE=0.0452, DPEAKS=49.8, Loss=0.00559]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/50]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 15: 100%|ââââââââââ| 307/307 [01:37<00:00,  3.14it/s, WMAPE=2.08, DICE=0.0467, DPEAKS=47.7, Loss=0.00566]\n",
            "Validate Epoch 15: 100%|ââââââââââ| 77/77 [00:09<00:00,  8.12it/s, WMAPE=2.04, DICE=0.046, DPEAKS=50.1, Loss=0.00524]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "early stopping: 3 epochs without improvement\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader = create_train_valid_loaders(\n",
        "    f\"partition_{current_partition}_train.json\",\n",
        "    f\"partition_{current_partition}_val.json\",\n",
        "    \"partitions\",\n",
        "    batch_size=16,\n",
        ")\n",
        "best_model_path = os.path.join(\n",
        "    \"models\", f\"best_model_partition_{current_partition}.pth\"\n",
        ")\n",
        "last_checkpoint_path = os.path.join(\n",
        "    \"models\", f\"last_checkpoint_partition_{current_partition}.pth\"\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    best_model_path,\n",
        "    last_checkpoint_path,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=50,\n",
        "    device=DEVICE,\n",
        "    early_stopping_patience=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validate Epoch test: 100%|ââââââââââ| 1941/1941 [04:00<00:00,  8.07it/s, WMAPE=1.51, DICE=0.043, DPEAKS=33.6, Loss=0.00451]\n",
            "Validate Epoch partition_7_train: 100%|ââââââââââ| 307/307 [00:42<00:00,  7.19it/s, WMAPE=1.52, DICE=0.0431, DPEAKS=34.7, Loss=0.00451]\n",
            "Validate Epoch partition_7_val: 100%|ââââââââââ| 77/77 [00:10<00:00,  7.23it/s, WMAPE=1.54, DICE=0.043, DPEAKS=33.5, Loss=0.00457]\n"
          ]
        }
      ],
      "source": [
        "#Cargar mejor modelo de la particion actual\n",
        "model.load_state_dict(torch.load(best_model_path,weights_only=True))\n",
        "test_model(model,criterion,device=DEVICE,batch_size=16)\n",
        "create_next_partitions(current_partition,model,criterion,device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
